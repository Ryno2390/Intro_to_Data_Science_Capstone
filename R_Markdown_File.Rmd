---
title: "R_Markdown_File"
author: "RStudio"
date: "10/9/2018"
output: html_document
URL: https://github.com/Ryno2390/Intro_to_Data_Science_Capstone.git
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Questions to Answer 

### What is the problem you want to solve?

Analyze the voting patterns of the US during the 2016 Presidential election - with a stretch goal of creating a prediction model of who would have won the 2016 Presidential election using FiveThirtyEight's election data. 

### Who is your client and why do they care about this problem? In other words, what will your client DO or DECIDE based on your analysis that they wouldnâ€™t have otherwise?

Generally speakig, lobbyists seek to "back a winning horse" - i.e. they intend to contribute as much money as possible, given their contribution budget constaint, to the winning candidate. Only the winning candidate gains political power, therefore lobbysts do not wish to diluate the power of their contibution budget by donating to multiple candidates in the same race. An accurate prediction model would enable lobbyst clients to make more informed donation decisions. 

### What data are you going to use for this? How will you acquire this data?

I will use FiveThirtyEight.com's data which is readily available through Kaggle (https://www.kaggle.com/fivethirtyeight/2016-election-polls#presidential_polls.csv)

### In brief, outline your approach to solving this problem (knowing that this might change later).

My approach will bet to understand FiveThirtyEight's model and to simplify the model as much as possible to conform with the goals of this course. I will then use the data to analyze regional voting patterns, with a stretch goal of creating a simplified model that can incorporate polling data to update it's prediction of who will win the election.

### What are your deliverables? Typically, this would include code, along with a paper and/or a slide deck.

The deliverables will include:

+ A walkthrough of the model using RMarkdown
+ A detailed summary paper that analyzes regional voting trends as well as a prediction of who would win

# Upload data into RStudio

```{r}
library(readr)

Raw_Data <- read_csv("presidential_polls.csv")

Raw_Data
```

There are many superfluous columns in this data set that are not useful for this project. These include:

+ cycle - all values are the same (i.e. set to "2016")

+ branch - all values are the same (i.e. set to "Presidential")

+ type - this determines which model FiveThirtyEight associates with each poll (i.e. "Now-Cast", "Polls-Only", or "Polls-Plus")

+ matchup - all values are the same (i.e. set to "Clinton vs. Trump vs. Johnson")

+ forecastdate - all values are the same (i.e. set to "11/1/2016")

+ rawpoll_johnson - my model will only compare voting patterns between the final two presidential candidates (i.e. Clinton or Trump) and therefore will exclude data for both Johnson and McMullin

+ rawpoll_mcmullin - my model will only compare voting patterns between the final two presidential candidates (i.e. Clinton or Trump) and therefore will exclude data for both Johnson and McMullin

+ adjpoll_johnson - my model will only compare voting patterns between the final two presidential candidates (i.e. Clinton or Trump) and therefore will exclude data for both Johnson and McMullin

+ adjpoll_mcmullin - my model will only compare voting patterns between the final two presidential candidates (i.e. Clinton or Trump) and therefore will exclude data for both Johnson and McMullin

+ multiversions - this field denotes if there were multiple versions of the same poll. My analysis will not make such a distinction and will simply take each poll at face value.

+ url - links to the original poll data location.

+ poll_id - unique identifier used by FiveThirtyEight cross-over use in other models.

+ question_id - unique identifer to determine the form of the poll question. I do not have access to the reference table for these questions so this will not be included in our data set.

+ createddate - date the data was inputted to the model. Irrelevant for my data set.

+ timestamp - date the model was rerun incorporating all the data up to that point. The model was last updated November 1st, 2018 and is irrelavnt to my data set.

This leaves the following fields in my data set:

+ state - the state from which the poll was taken (the value "U.S." signifies a national poll)

+ startdate - the date for which the poll was begun

+ enddate - the date for which the poll was ended

+ pollster - the organization that conducted the poll

+ grade - the accuraacy rating of the polling organization, as determined by FiveThirtyEight by analyzing past predictions and comparing them to actual results.

+ samplesize - the size of the sample for the poll (i.e. the "n" value)

+ population - ???

+ poll_wt - the weight assigned to each poll predicated on the polling organization's grade

+ rawpoll_clinton - the raw percentage of respondents polled who plan on voting for Hillary Clinton

+ rawpoll_trump - the raw percentage of respondents polled who plan on voting for Donald Trump

+ adjpoll_clinton - the weight adjusted percentage of respondents polled who plan on voting for Hillary Clinton

+ adjpoll_trump - the weight adjusted percentage of respondents polled who plan on voting for Donald Trump

# Remove superfluous columns from the data set to produce a clean data set

```{r}
library(dplyr)

Clean_Data <- Raw_Data %>% select(-c(cycle:forecastdate, rawpoll_johnson, rawpoll_mcmullin, adjpoll_johnson:timestamp))

Clean_Data
```

A quick overview of the "state" column reveals that there are really two different types of polls: purely state polls (which include specific congressional districts, as well as state-wide polls) and national polls. To get our bearings I will apply some statistics to the purely national polls at first; we will analyze regional variations in polling later.

# Filter the data to include only "U.S." - or national - polls

```{r}
library(dplyr)
install.packages("lubridate")
library(lubridate)

National_Polls <- Clean_Data %>% 
  select(state, enddate, samplesize, rawpoll_clinton, rawpoll_trump) %>%
  filter(state == "U.S.") %>%
  mutate(enddate = mdy(enddate)) %>%
  arrange(enddate)

National_Polls
```

Now that we have the data we need we can do a simply scatter plot of the the rawpoll_clinton and rawpoll_trump fields over time (i.e. by enddate) to see if there are any patterns. Let's start with Clinton's raw polling data.

# Install ggplot2 and plot the rawpoll_clinton data over time to see if there are any obvious patterns.

```{r}
install.packages("ggplot2")
library("ggplot2")

ggplot(data = National_Polls, aes(x=enddate, y=rawpoll_clinton)) +
  geom_point()
```

Now, let's do the same for Trump's raw polling data.

# Plot the rawpoll_trump data over time to see if there are any obvious patterns.

```{r}
ggplot(data = National_Polls, aes(x=enddate, y=rawpoll_trump)) +
  geom_point()
```

One obvious pattern that stands out is that the number of polls increases over time. This makes sense, since as we get closer to election day, more and more polls are conducted in order to determine who the likely winner will be. Another obvious pattern is that the variation in the polls also increase over time - like a funnel that widens over time. 

Perhaps the most important point to make about the data is that it is quite "noisy" - even temporally close polls can drastically differ in outcome. Smoothing out the data could be helpful in teasing out a meaningful pattern. One potentially useful smoothing technique is a moving average - a rolling average of all polls taken within a certain time frame. A moving average can help us find the "signal" among the "noise".

Let's apply a 100 poll moving average to Clinton's raw polling data and plot it over time. This will provide us with a moving average of the last 100 polls.

```{r}
install.packages("zoo")
library(zoo)

National_Polls <- National_Polls %>%
  mutate(Clinton_MA = rollmean(rawpoll_clinton, 100, na.pad=TRUE, align="right"))

ggplot(data = National_Polls, aes(x=enddate, y=Clinton_MA)) +
  geom_line()
```

Let's now do the same for Trump's raw polling data.

```{r}
National_Polls <- National_Polls %>%
  mutate(Trump_MA = rollmean(rawpoll_trump, 100, na.pad=TRUE, align="right"))

ggplot(data = National_Polls, aes(x=enddate, y=Trump_MA)) +
  geom_line()
```

After smoothing out the data we can see some clear patterns. Early on in the cycle it appears that Clinton had an early and substantial lead in the polls (though this is tempered by the fact that there were fewer polls during this earlier period). However, this early and substantial lead appears to erode over the summer, improving in the fall but never regaining those early leads. In contrast, Trump's polling data improved over time, starting around July, and spiking in the final weeks of the cycle.

Another helpful way of looking at the data is by calculating a margin. So far, the data has been separated into columns for each candidate. Though this is useful, what really matters in elections is which candidate wins a higher percentage of the vote. In other words, what we want to know is the margin between Clinton and Trump.

Since Clinton was favored to win early on, we will subtract Trump's polling figures from Clinton's to arrive at our Margin figure - but we could just as easily done the opposite.

# Calculate the Clinton - Trump margin and plot it over time.

```{r}
National_Polls <- National_Polls %>%
  mutate(Clinton_Margin = Clinton_MA - Trump_MA)

ggplot(National_Polls, aes(x=enddate, y=Clinton_Margin)) +
  geom_line()
```

Using this visualization of margin we can see more clearly the pattern in Clinton's chances of winning the presidency. We see an early rise in her chances as she widened her margin from January through May; however, her chances deteriorated throughout the Summer and Fall - reaching their lowest point in August (where it was actually net negative for the first time), only to regain in mid-September through mid-October period, preciptously falling back down in late October. If this late, falling trend were extended through election day (i.e. November 6th, 2016), it's entirely plausible that Clinton would have had a net negative margin on election day.